{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import math\n",
    "import numpy as np\n",
    "nlp = spacy.load('en')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1 = open(\"/Users/sumeetmishra/Desktop/ThirdSem/ANLP/Assignments/5/ex1.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Use for example spaCy to segment the text in file ex1.txt into a list of sentences. Identify the sentence in the text.Submit fully functional code that reads the text from the file, segments the text into sentences, and computes the similarity score between each sentence and the seed sentence above. You can use spaCy for the sentence segmentation task and there are tutorials online that describe that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ex1.read()\n",
    "sentences = sentences.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence.\n",
      "This is another sentence.\n",
      "John likes milk.\n",
      "Peter eats candy.\n",
      "My dog likes bones.\n"
     ]
    }
   ],
   "source": [
    "tokenize = nlp(sentences)\n",
    "for i in tokenize.sents:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence. 0.5667826716312883\n",
      "This is another sentence. 0.5666846478630649\n",
      "John likes milk. 0.6670014311494377\n",
      "Peter eats candy. 0.6260620693266784\n",
      "My dog likes bones. 0.7090515301353888\n",
      "The most similar sentence is:  My dog likes bones.\n"
     ]
    }
   ],
   "source": [
    "sentence = nlp(u\"My poodle likes food in general.\")\n",
    "max = 0\n",
    "for i in tokenize.sents:\n",
    "    score = i.similarity(sentence)\n",
    "    print(i,score)\n",
    "    if score > max:\n",
    "        max = score\n",
    "        mss = i\n",
    "        \n",
    "print(\"The most similar sentence is: \", mss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.(a)  Write Python code to identify the most similar words in the two sentences using any of your selected Python NLP modules and a loop over the tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = nlp(u\"John loves apples\")\n",
    "sentence2 = nlp(u\"some man likes fruit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similar words are: loves and likes\n"
     ]
    }
   ],
   "source": [
    "max = 0\n",
    "result = []\n",
    "\n",
    "for w in sentence1:\n",
    "    for w1 in sentence2:\n",
    "        v1 = w.vector\n",
    "        v2 = w1.vector\n",
    "        a = 0\n",
    "        score = w.similarity(w1)\n",
    "        \n",
    "        for i,j in zip(v1,v2):\n",
    "            a += math.pow((i-j),2)\n",
    "        \n",
    "        result.append(math.sqrt(a))\n",
    "        \n",
    "        if score > max:\n",
    "            max = score\n",
    "            word1 = w\n",
    "            word2 = w1\n",
    "\n",
    "print(\"The similar words are:\",word1,\"and\",word2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.(b) For the most similar words that you identified in a., write Python code that computes the distance between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Euclidean distance is 27.25827088137728\n"
     ]
    }
   ],
   "source": [
    "distance = 0\n",
    "v3 = word1.vector\n",
    "v4 = word2.vector\n",
    "for i,j in zip(v3,v4):\n",
    "    distance += math.pow((i-j),2)\n",
    "print(\"The Euclidean distance is\",math.sqrt(distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.(c). Sum up and average over the distances to print out the Word Mover's Distance between the two lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word mover's distance is: 34.70335297065183\n"
     ]
    }
   ],
   "source": [
    "print(\"The word mover's distance is:\",np.mean(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Select a target text with more than 500 words. Segment the text into sentences. Parse each sentence using a Dependency Parser (only in spaCy or CoreNLP, maybe in textblob). Use the Dependency Parser output and map out all occurrences of: Subject - Verb - Object. Write down the steps that are necessary to extract this information from the NLP-pipeline output. Write the Python code that generates these triples from the text you selected. Generate all triples and submit the example text, the Python code, and the result file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/sumeetmishra/Desktop/ThirdSem/ANLP/Assignments/5/five_hundred_words.txt\",\"r+\") as f:\n",
    "    corpus = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_c = nlp(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  Far far away, behind the word mountains, far from the countries Vokalia and Consonantia, there live the blind texts.\n",
      "Subject:  []\n",
      "Object:  [texts]\n",
      "Verb:  [live]\n",
      "Sentence:  Separated they live in Bookmarksgrove right at the coast of the Semantics, a large language ocean.\n",
      "Subject:  [they]\n",
      "Object:  []\n",
      "Verb:  [Separated, live]\n",
      "Sentence:  A small river named Duden flows by their place and supplies it with the necessary regelialia.\n",
      "Subject:  [river]\n",
      "Object:  [it]\n",
      "Verb:  [named, supplies]\n",
      "Sentence:  It is a paradisematic country, in which roasted parts of sentences fly into your mouth.\n",
      "Subject:  [It, parts]\n",
      "Object:  []\n",
      "Verb:  [is, roasted, fly]\n",
      "Sentence:  Even the all-powerful Pointing has no control about the blind texts it is an almost unorthographic life One day however a small line of blind text by the name of Lorem Ipsum decided to leave for the far World of Grammar.\n",
      "Subject:  [Pointing, it, line]\n",
      "Object:  [control]\n",
      "Verb:  [has, is, decided, leave]\n",
      "Sentence:  The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn’t listen.\n",
      "Subject:  [Oxmox, Text]\n",
      "Object:  [her]\n",
      "Verb:  [advised, do, were, listen]\n",
      "Sentence:  She packed her seven versalia, put her initial into the belt and made herself on the way.\n",
      "Subject:  [She]\n",
      "Object:  [versalia, initial, herself]\n",
      "Verb:  [packed, put, made]\n",
      "Sentence:  When she reached the first hills of the Italic Mountains, she had a last view back on the skyline of her hometown Bookmarksgrove, the headline of Alphabet Village and the subline of her own road, the Line Lane.\n",
      "Subject:  [she, she]\n",
      "Object:  [hills, view]\n",
      "Verb:  [reached, had]\n",
      "Sentence:  Pityful a rethoric question ran over her cheek, then she continued her way.\n",
      "Subject:  [question, she]\n",
      "Object:  []\n",
      "Verb:  [ran, continued]\n",
      "Sentence:  On her way she met a copy.\n",
      "Subject:  [she]\n",
      "Object:  [copy]\n",
      "Verb:  [met]\n",
      "Sentence:  The copy warned the Little Blind Text, that where it came from it would have been rewritten a thousand times and everything that was left from its origin would be the word \"and\" and the Little Blind Text should turn around and return to its own, safe country.\n",
      "Subject:  [copy, it, everything, Text]\n",
      "Object:  [Text]\n",
      "Verb:  [warned, came, been, rewritten, was, left, be, turn, return]\n",
      "Sentence:  But nothing the copy said could convince her\n",
      "Subject:  [nothing, copy]\n",
      "Object:  [her]\n",
      "Verb:  [said, convince]\n",
      "Sentence:  and so it didn’t take long until a few insidious Copy Writers ambushed her,\n",
      "Subject:  [it, Writers]\n",
      "Object:  [her]\n",
      "Verb:  [take, ambushed]\n",
      "Sentence:  made her drunk with Longe and Parole and dragged her into their agency, where they abused her for their projects again and again.\n",
      "Subject:  [her, they]\n",
      "Object:  [her, her]\n",
      "Verb:  [made, dragged, abused]\n",
      "Sentence:  And if she hasn’t been rewritten, then they are still using her.\n",
      "Subject:  [they]\n",
      "Object:  [her]\n",
      "Verb:  [been, rewritten, using]\n",
      "Sentence:  Far far away, behind the word mountains, far from the countries Vokalia and Consonantia, there live the blind texts.\n",
      "Subject:  []\n",
      "Object:  [texts]\n",
      "Verb:  [live]\n",
      "Sentence:  Separated they live in Bookmarksgrove right at the coast of the Semantics, a large language ocean.\n",
      "Subject:  [they]\n",
      "Object:  []\n",
      "Verb:  [Separated, live]\n",
      "Sentence:  A small river named Duden flows by their place and supplies it with the necessary regelialia.\n",
      "Subject:  [river]\n",
      "Object:  [it]\n",
      "Verb:  [named, supplies]\n",
      "Sentence:  It is a paradisematic country, in which roasted parts of sentences fly into your mouth.\n",
      "Subject:  [It, parts]\n",
      "Object:  []\n",
      "Verb:  [is, roasted, fly]\n",
      "Sentence:  Even the all-powerful Pointing has no control about the blind texts it is an almost unorthographic life One day however a small line of blind text by the name of Lorem Ipsum decided to leave for the far World of Grammar.\n",
      "Subject:  [Pointing, it, line]\n",
      "Object:  [control]\n",
      "Verb:  [has, is, decided, leave]\n",
      "Sentence:  The Big Oxmox advised her not to do so, because there were thousands of bad Commas, wild Question Marks and devious Semikoli, but the Little Blind Text didn’t listen.\n",
      "Subject:  [Oxmox, Text]\n",
      "Object:  [her]\n",
      "Verb:  [advised, do, were, listen]\n",
      "Sentence:  She packed her seven versalia, put her initial into the belt and made herself on the way.\n",
      "Subject:  [She]\n",
      "Object:  [versalia, initial, herself]\n",
      "Verb:  [packed, put, made]\n",
      "Sentence:  When she reached the first hills of the Italic Mountains, she had a last view back on the skyline of her hometown Bookmarksgrove, the headline of Alphabet Village and the subline of her own road, the Line Lane.\n",
      "Subject:  [she, she]\n",
      "Object:  [hills, view]\n",
      "Verb:  [reached, had]\n"
     ]
    }
   ],
   "source": [
    "result1 = ''\n",
    "for sentence in nlp_c.sents:\n",
    "    x = sentence.text\n",
    "    token = nlp(x)\n",
    "    subject = []\n",
    "    object = []\n",
    "    verb = []\n",
    "    for i in token:\n",
    "        if(i.dep_ == \"nsubj\"):\n",
    "            subject.append(i)\n",
    "        if(i.dep_ == \"dobj\"):\n",
    "            object.append(i)\n",
    "        if(i.pos_ == \"VERB\" and i.dep_ != \"aux\"):\n",
    "            verb.append(i)\n",
    "    print(\"Sentence: \",x)\n",
    "    print(\"Subject: \",subject)\n",
    "    print(\"Object: \",object)\n",
    "    print(\"Verb: \",verb)\n",
    "    \n",
    "    result1 += \"Sentence: \" + str(x) + \"Subject: \" + str(subject) + \"Object: \" + str(object) + \"Verb: \" + str(verb)\n",
    "\n",
    "with open(\"final_result.txt\",\"w+\") as f:\n",
    "    f.write(result1)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
